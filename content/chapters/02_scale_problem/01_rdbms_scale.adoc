== Scaling, Old School

When I got interested in Cassandra, I was working at some startups that had tried to build scalable systems with tight SLAs and had run into some trouble.  This was a point in time when using a relational database and vertical scaling was the tried and true solution.

Once we hit the limits of vertical scaling, the next step was to chip away at the advantages of the RDBMS.

=== Caching

The first (and easiest) problem that needed to be solved was dealing with read heavy workload.  Fortunately, solving reads is usually solved by making more copies of the data and using more servers, in the form of caching.

Caching servers are easily scaled by partitioning the data among all the servers.  Splitting data among caching servers is easy.   This works great for read heavy workloads and scales linearly for a long time.

You've probably heard of one of the most well known caching projects of all time, Memcached.  Memcached made it possible to massively scale read heavy workloads by exposing a simple api.  The Memcached api only exposes a simple key/value api for setting and retrieving data.  The following (crappy) code shows the basic logic:

```python
def get_something(id):
    tmp = memcached.get(key)
    if(tmp):
        return tmp
    result = db.query("SELECT * from stuff WHERE id = " + id)
    memcached.put(key, result)
    return result
```

This is fine for small objects / rows, but doesn't work so well with large datasets that are joined and aggregated.  How do we know what cache items to expire when a single row changes?  We still have a problem with more complex workloads.

As the system grows and our SLAs remain the same, we have to start using optimizations to avoid performing the costly operations.  Instead of using expensive joins, we denormalize and copy data around to avoid the costly join.  Instead of aggregating on the fly we precalculate statistics.  We can skip grouping hundreds of thousands (or millions) and return a handful of rows, which can be orders of magnitude faster than trying to do the calculation on the fly.

We start thinking about partitioning our data at this point.  Without joins, we can move tables to different machines without much problem.  We lose the ability to d

querying single table

querying single rows

Hello

Once we've
